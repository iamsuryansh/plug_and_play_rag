# AI Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# LLM Provider Configuration
# Options: gemini, ollama, lmstudio, openai-compatible, custom
LLM_PROVIDER=gemini

# Generic LLM settings (used for custom providers)
LLM_MODEL_NAME=
LLM_ENDPOINT_URL=
LLM_API_KEY=

# Ollama Configuration (for local Ollama server)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama2

# LM Studio Configuration (for local LM Studio server)
LMSTUDIO_ENDPOINT=http://localhost:1234
LMSTUDIO_MODEL=local-model

# Database Configuration (Optional)
DATABASE_URL=postgresql://user:password@localhost/dbname
MONGODB_URL=mongodb://localhost:27017/database

# Application Settings
DEBUG=true
LOG_LEVEL=INFO

# Kafka Configuration (Optional)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Redis Configuration (Optional)  
REDIS_URL=redis://localhost:6379

# Worker Configuration
INGESTION_WORKERS=2
EMBEDDING_WORKERS=3
